---
layout: 2021
title: High Performance Graphics 2021 &#8211; Program
description: High Performance Graphics 2021 Program
keywords: conference, program, graphics, performance, ray-tracing, raytracing, GPU
---
<h1>Program</h1>
<p>All times are given in US Pacific daylight time: UTC -7</p>
<h2><b>Tuesday, July 6  [<a href="https://youtu.be/eGfX1iWzkh0">YouTube stream</a>]</b></h2>
<table>
<tbody>
<tr>
<td>9:00-9:10</td>
<td><a href="https://www.youtube.com/watch?v=eGfX1iWzkh0&amp;t=691s"><b>HPG 2021 Opening</b></a></td>
</tr>
<tr>
<td>9:10-10:05</td>
<td><b><a href="https://www.youtube.com/watch?v=eGfX1iWzkh0&amp;t=1222s">Keynote: Alex Evans (NVIDIA)</a><br />
Optimising for Artist Happiness<br />
</b></td>
</tr>
<tr>
<td>10:05-10:13</td>
<td><b>Break</b></td>
</tr>
<tr>
<td>10:13-10:25</td>
<td><a href="https://www.youtube.com/watch?v=eGfX1iWzkh0&amp;t=5108s"><b>Papers Fast Forward</b></a></td>
</tr>
<tr>
<td>10:25-11:40</td>
<td><b><a href="https://www.youtube.com/watch?v=eGfX1iWzkh0&amp;t=5665s">Technical Papers: High-Performance Rendering</a><br />
Session Chair: Christoph Peters (Karlsruhe Institute of Technology)<br />
</b></p>
<ul>
<li><a href="https://diglib.eg.org/handle/10.1111/cgf14377">Hardware Adaptive High Order Interpolation for Real-Time Graphics</a><br />
<i>Daqi Lin, Larry Seiler, Cem Yuksel</i><br />
<a href="https://www.youtube.com/watch?v=eGfX1iWzkh0&amp;t=5727s">Video</a></li>
</ul>
<ul>
<li><a href="https://diglib.eg.org/handle/10.2312/hpg20211279">Transfer-Function-Independent Acceleration Structure for Volume Rendering in Virtual Reality<br />
</a><i>Balázs Faludi, Norbert Zentai, Marek Żelechowski, Azhar Zam, Georg Rauter, Mathias Griessen, Philippe Cattin<br />
</i><a href="https://www.youtube.com/watch?v=eGfX1iWzkh0&amp;t=7382s">Video</a></li>
</ul>
<ul>
<li><a href="https://diglib.eg.org/handle/10.2312/hpg20211280">Multi-Resolution Shared Representative Filtering for Real-Time Depth Completion<br />
</a><i>Yu-Ting Wu, Tzu-Mao Li, I-Chao Shen, Hong-Shiang Lin, Yung-Yu Chuang<br />
</i><a href="https://www.youtube.com/watch?v=eGfX1iWzkh0&amp;t=8976s">Video</a></li>
</ul>
</td>
</tr>
<tr>
<td>11:40-13:40</td>
<td><a href="https://www.youtube.com/watch?v=eGfX1iWzkh0&amp;t=10624s"><b>Diversity in High Performance Graphics</b></a></p>
<ul>
<li>Dr. Apollo Ellis</li>
<li>Noshaba Cheema</li>
<li>Tony Baylis</li>
<li>Dr. Kevin Griffin</li>
<li>Dr. Diana Arellano</li>
<li>Daniel Pills</li>
<li>Natalie Rountree-Bell</li>
<li>Seth Izen</li>
</ul>
<p>Please find a bio for panel members below</td>
</tr>
</tbody>
</table>
<h2><b>Wednesday, July 7 [<a href="https://www.youtube.com/watch?v=kI5uEMXvreY">YouTube stream</a>]</b></h2>
<table>
<tbody>
<tr>
<td>9:00-9:05</td>
<td><a href="https://www.youtube.com/watch?v=kI5uEMXvreY&amp;t=959s"><b>Sponsor Intel</b></a></td>
</tr>
<tr>
<td>9:05-10:15</td>
<td><b>Invited Talks:</b></p>
<p><b><a href="https://www.youtube.com/watch?v=kI5uEMXvreY&amp;t=1361s">Carsten Benthin (Intel) &amp; Ingo Wald (NVIDIA)</a><br />
Embree “There and back again…”</b></p>
<p><a href="https://www.youtube.com/watch?v=kI5uEMXvreY&amp;t=3636s"><b>Karl Leiss &amp; Matteo Marone (BIT Technology Solutions)</b></a><br />
<b>Grand challenges in synthetic radar data generation for AI<br />
</b></td>
</tr>
<tr>
<td>10:15-10:30</td>
<td><b>Break</b></td>
</tr>
<tr>
<td>10:30-10:35</td>
<td><a href="https://www.youtube.com/watch?v=kI5uEMXvreY&amp;t=6523s"><b>Poster Fast Forward</b></a></td>
</tr>
<tr>
<td>10:35-11:50</td>
<td><b><a href="https://www.youtube.com/watch?v=kI5uEMXvreY&amp;t=6982s">Technical Papers: Rendering</a><br />
Session Chair: Anton Kaplanyan (Facebook Reality Labs)<br />
</b></p>
<ul>
<li><a href="https://diglib.eg.org/handle/10.1111/cgf14378">ReSTIR GI: Effective Path Resampling for Real-Time Path Tracing</a><br />
<i>Yaobin Ouyang, Shiqiu Liu, Markus Kettunen, Matt Pharr, Jacopo Pantaleoni<br />
</i><a href="https://www.youtube.com/watch?v=kI5uEMXvreY&amp;t=7001s">Video</a></li>
</ul>
<ul>
<li><a href="https://diglib.eg.org/handle/10.1111/cgf14379">BRDF Importance Sampling for Linear Lights<br />
</a><i>Christoph Peters<br />
</i><a href="https://www.youtube.com/watch?v=kI5uEMXvreY&amp;t=8663s">Video</a></li>
</ul>
<ul>
<li><a href="https://diglib.eg.org/handle/10.2312/hpg20211281">Rearchitecting Spatiotemporal Resampling for Production<br />
</a><i>Chris Wyman, </i><i>Alexey </i><i>Panteleev<br />
</i><a href="https://www.youtube.com/watch?v=kI5uEMXvreY&amp;t=10153s">Video</a></li>
</ul>
</td>
</tr>
<tr>
<td>11:50</td>
<td><b>Social Mixer (Premium registrant-only)</b></td>
</tr>
</tbody>
</table>
<h2><b>Thursday, July 8 [<a href="https://www.youtube.com/watch?v=L8IfdFokzDA">YouTube stream</a>]</b></h2>
<table>
<tbody>
<tr>
<td>9:00-9:05</td>
<td><a href="https://www.youtube.com/watch?v=L8IfdFokzDA&amp;t=920s"><b>Sponsor Unity</b></a></td>
</tr>
<tr>
<td>9:05-10:15</td>
<td><b>Invited Talks:</b></p>
<p><b><a href="https://www.youtube.com/watch?v=L8IfdFokzDA&amp;t=1200s">Anders Drachen (University of York)</a><br />
Fireballs and Lightning: Visualising Esports Experiences<br />
</b></p>
<p><strong>Belen Masia (University of Zaragoza)</strong><br />
<strong>Modeling user behavior for improved virtual reality applications</strong></td>
</tr>
<tr>
<td>10:15-10:30</td>
<td><b>Break</b></td>
</tr>
<tr>
<td>10:30-11:45</td>
<td><b><a href="https://www.youtube.com/watch?v=L8IfdFokzDA&amp;t=3903s">Technical Papers: Compression</a><br />
Session Chair: Tamy Boubekeur (Ecole Polytechnique/Telecom Paris/Adobe Research)<br />
</b></p>
<ul>
<li><a href="https://diglib.eg.org/handle/10.2312/hpg20211282">Vertex-Blend Attribute Compression<br />
</a><i>Bastian Kuth, Quirin Meyer</i><br />
<a href="https://www.youtube.com/watch?v=L8IfdFokzDA&amp;t=3920s">Video</a></li>
</ul>
<ul>
<li><a href="https://diglib.eg.org/handle/10.2312/hpg20211283">Directed acyclic graph encoding for compressed shadow maps<br />
</a><i>Leonardo Scandolo, Elmar Eisemann<br />
</i><a href="https://www.youtube.com/watch?v=L8IfdFokzDA&amp;t=5710s">Video</a></li>
</ul>
<ul>
<li><a href="https://diglib.eg.org/handle/10.2312/hpg20211284">Compression and Rendering of Textured Point Clouds via Sparse Coding<br />
</a><i>Kersten Schuster, Philip Trettner, Patric Schmitz, Julian Schakib, Leif Kobbelt</i><br />
<a href="https://www.youtube.com/watch?v=L8IfdFokzDA&amp;t=7290s">Video</a></li>
</ul>
</td>
</tr>
<tr>
<td>11:45-12:30</td>
<td><b>Poster Session (Premium registrant-only)</b></p>
<ul>
<li>Dynamic Reflections Using Eye-Resolution Point Rendering<br />
<em><em>Ajinkya Gavane and Ben Watson</em></em></li>
<li>Accelerating Space Compression Algorithms on Embedded GPUs<br />
<em><em>Álvaro Jover-Álvarez, Ivan Rodriguez Ferrández, Leonidas Kosmidis and David Steenari</em></em></li>
<li>Virtual Lights with Blue Noise Distribution<br />
<em><em>Tianyu Li, Wenyou Wang, Daqi Lin and Cem Yuksel</em></em></li>
<li>Opportunities to Avoid Texture Lookups in Modern Game Frames<br />
<em>Aditya Ukarande, Deep Shekhar and Ram Rangan</em></li>
</ul>
</td>
</tr>
</tbody>
</table>
<h2><b>Friday, July 9 [<a href="https://youtu.be/_qXATz_1fcw">YouTube stream</a>]</b></h2>
<table>
<tbody>
<tr>
<td>8:45-10:15</td>
<td><b>HPG Town Hall (Premium registrant-only)</b></td>
</tr>
<tr>
<td>10:15-10:20</td>
<td><b>Break</b></td>
</tr>
<tr>
<td>10:20-11:35</td>
<td><b><a href="https://www.youtube.com/watch?v=_qXATz_1fcw&amp;t=964s">Technical Papers: Geometry and Optimization</a><br />
Session Chair: Michael Doggett (Lund University)<br />
</b></p>
<ul>
<li><a href="https://diglib.eg.org/handle/10.1111/cgf14380">Sampling from Quadric-Based CSG Surfaces</a><br />
<i>Philip Trettner, Leif Kobbelt<br />
</i><a href="https://www.youtube.com/watch?v=_qXATz_1fcw&amp;t=971s">Video</a></li>
</ul>
<ul>
<li><a href="https://diglib.eg.org/handle/10.1111/cgf14381">A Halfedge Refinement Rule for Parallel Catmull-Clark Subdivision</a><br />
<i>Jonathan Dupuy, Kenneth Vanhoey</i><br />
<a href="https://www.youtube.com/watch?v=_qXATz_1fcw&amp;t=2425s">Video</a></li>
</ul>
<ul>
<li><a href="https://diglib.eg.org/handle/10.1111/cgf14382">Cooperative Profile Guided Optimizations</a><br />
<i>Mark Stephenson, Ram Rangan, Stephen Keckler<br />
</i><a href="https://www.youtube.com/watch?v=_qXATz_1fcw&amp;t=4158s">Video</a></li>
</ul>
</td>
</tr>
<tr>
<td>11:35-11:50</td>
<td><b>Break</b></td>
</tr>
<tr>
<td>11:50-12:00</td>
<td><b>Student Competition</b></p>
<ul>
<li><a href="https://www.highperformancegraphics.org/studcomp21/3DUrbanRT/">Efficient Ray-Tracing for Urban Radiation Source Localization</a><br />
<em>Andrew Hollis and Ajinkya Gavane, North Carolina State University<br />
</em><a href="https://www.youtube.com/watch?v=_qXATz_1fcw&amp;t=6756s">Video</a></li>
<li><a href="https://www.highperformancegraphics.org/studcomp21/MeshFrame/">MeshFrame: a Light Weighted Dynamic Mesh Processing FrameWork</a><br />
<em>He (Anka) Chen, University of Utah</em><br />
<a href="https://www.youtube.com/watch?v=_qXATz_1fcw&amp;t=6946s">Video</a></li>
</ul>
</td>
</tr>
<tr>
<td>12:00-13:00</td>
<td><b><a href="https://www.youtube.com/watch?v=_qXATz_1fcw&amp;t=7445s">Keynote: Karan Singh (University of Toronto)</a><br />
High performance Interfaces for Modeling, Animation and more…<br />
</b></td>
</tr>
<tr>
<td>13:00-13:20</td>
<td><a href="https://www.youtube.com/watch?v=_qXATz_1fcw&amp;t=10715s"><b>Closing remarks</b></a></td>
</tr>
<tr>
<td>13:20</td>
<td><b>OhYay Party (Premium registrant-only)</b></td>
</tr>
</tbody>
</table>
<h3>Day 1:</h3>
<h4>9:10 &#8211; Keynote: <b>Optimising for Artist Happiness</b> (Alex Evans)</h4>
<p><strong>Abstract</strong>: There are many approaches to and customers of graphics research, each with different needs. My background in graphics began in the Demoscene, where one only needed to tune your algorithms for the best, prettiest case; The majority of my career, however, was spent in the games industry, building tools for millions of creative users – artists. When you only have loose control over how your algorithms are applied, there is only one choice: to concentrate on the worst case. In this talk, I’d like to convince you that doing so is worthwhile, and ends up being equivalent to ‘optimising for artist happiness’. I’ll illustrate the idea with examples from my past work and finally ask the question: what place do volumetric geometry techniques have in the future of high performance graphics?</p>
<p><strong>Alex Evans</strong></p>
<p>Bio: Alex Evans was a cofounder and technical director of MediaMolecule, a game studio best known for its work in “creative gaming,” with titles including LittleBigPlanet and Dreams, which brought to a wide audience a set of creative tools built on Signed Distance Fields. He joined NVIDIA Research at the end of 2020.</p>
<p><img loading="lazy" class="alignnone size-medium wp-image-129" src="/assets/images/2021/Alex-200x300.jpg" alt="" width="200" height="300" srcset="/assets/images/2021/Alex-200x300.jpg 200w, /assets/images/2021/Alex.jpg 320w" sizes="(max-width: 200px) 100vw, 200px" /></p>
<h4>11:40-13:40 &#8211; Diversity in High Performance Graphics</h4>
<p><strong>Dr. Apollo Ellis</strong><br />
Dr. Apollo Ellis is a long time HPG attendee, previous winner of an HPG best paper runner up award, and graduate of UC Berkeley CS (BA), UT Austin CS (MS), and UIUC CS (Ph.D). He helped found and direct the HPG diversity scholarship program and served on the HPG committee for the last four years. He currently works at Nvidia on the Omniverse rendering team, as a senior ray tracing engineer.</p>
<p><strong>Noshaba Cheema</strong><br />
Noshaba Cheema received her M.Sc. degrees in Visual Computing, as well as in Computer Science from Saarland University. Before that she completed her Undergraduate studies in Media Informatics at the Hochschule Bremen and NYU Tandon School of Engineering. She has received a Woman STEM Award in Artificial Intelligence from Deutsche Telekom and a best poster award from the Symposium on Computer Animation for her publications. Furthermore, she has won various scholarships for her studies including a Max-Planck Master Fellowship. Currently, Noshaba is a Ph.D. candidate at the Max-Planck Institute for Informatics and a researcher in the Agents and Simulated Reality group at the German Research Center for Artificial Intelligence (DFKI), where she is working on making AI characters dance and interact with humans in virtual and augmented reality. She has various volunteering experiences including SIGGRAPH, SIGGRAPH Asia, NeuRIPS and NVIDIA GTC among others. Noshaba has been on the HPG diversity committee as a co-chair since 2019.</p>
<p><strong>Tony Baylis</strong><br />
Tony Baylis is a senior leader, partner, and advocate for Diversity, Equity and Inclusion (DEI)<br />
programs and activities for Lawrence Livermore National Laboratory (LLNL). Tony manages<br />
the Laboratory’s strategic interactions and execution in building a diverse, equity, and inclusive workforce at LLNL. He collaborates with academia, government, industry, community, and<br />
diversity organization stakeholders. Tony represents the Laboratory on the subjects of DEI, science, engineering, arts, and mathematics (STEAM), outreach, and student programs.<br />
Tony is also the Diversity, Equity and Inclusion Committee Chair for ACM SIGGRAPH. His career represents 35 years of administrative, project, program, technical, organizational management and senior leadership in industry, academia, government, broadcast media, scientific and technical environments.</p>
<p><strong>Dr. Kevin Griffin</strong><br />
Dr. Kevin Griffin is a Senior Developer Technology Engineer at NVIDIA where he is working on the integration of scientific visualization software with NVIDIA’s Omniverse platform and a high-level API called ANARI (Analytic Rendering Interface) that supports diverse rendering backends. Kevin has previously worked at Lawrence Livermore National Laboratory where he was a Software Engineer and Solutions Executive for the High-Performance Computing Innovation Center. Kevin is also an Adjunct Associate Professor at San Joaquin Delta College where he teaches computer science courses. Dr. Griffin has a Diversity and Inclusion certification from Cornell University ILR school and is currently serving on ACM SIGGRAPH’s Diversity and Inclusion committee and the Research Posters committee for SC21. Kevin received a B.S. in computer science from the University of Delaware, an M.S. in computer science from the University of Tulsa and a Ph.D. in computer science from the University of California, Davis.</p>
<p><strong>Dr. Diana Arellano</strong><br />
Dr. Diana Arellano is currently the CGI-Development Chapter Lead and Scrum Master at Mackevision &#8211; part of Accenture Interactive in Stuttgart, Germany. As Chapter Lead she gets to work closely with the teams in disciplinary and organizational aspects, while keeping them agile.<br />
Diana also co-organizes discussion panels on Women in CG and Visual Arts at FMX and SIGGRAPH. Her volunteer journey with SIGGRAPH and ACM SIGGRAPH started in 2007 as Student Volunteer, where she went on to serve as Team Leader. She has also held the roles of International Resources Committee (IRC) Chair, External Relations Committee Chair and is currently an active member of the ACM SIGGRAPH Diversity and Inclusion Committee. Diana has been appointed as the SIGGRAPH 2022 Student Volunteers Program Chair.</p>
<p><strong>Daniel Pills</strong><br />
D. Pillis (they/them/he/him) is a new media artist and queer media archeologist who works with robotics, computer graphics and large scale installations to think about gender, sexuality and identity. They have been a member of ACM’s SIGGRAPH’s Diversity &amp; Inclusivity Summit since its founding in 2016. Recently, they have taught at Princeton University, Virginia Tech, and most recently completed graduate studies at Carnegie Mellon University in Pittsburgh Pennsylvania, where they studied with the father of computer graphics, Dr. Ivan Sutherland.</p>
<p><strong>Natalie Rountree-Bell</strong><br />
Natalie Rountree-Bell is a Middle Tennessee State Tennessee graduate with a focus in animation and fine art. After graduation, Natalie volunteered for ACM SIGGRAPH expanding diversity for people with disabilities. Her volunteerism with ACM SIGGRAPH began as a Student Volunteer in 2014 and Team Leader 2015, 2016, 2017. In 2019, she was able to create a focus area with Dylan Moore and see adaptive technology be at the forefront. She also has been able to serve on the first ACM SIGGRAPH DEI subcommittee, one of her favorite things she has done in her career. Natalie is currently living in Murfreesboro with her husband, dog, and cat, while working as a personal assistant for Christopher R. Harris photography. She has cerebral palsy, pushing everyday to make the world an accessible place as a “Palsy Champ”.</p>
<p><strong>Seth Izen</strong><br />
Seth Izen is a 3D Lighting and Compositing Artist, based in Los Angeles, CA. He currently works at Halon Entertainment as part of the Fortnite keyart team, in partnership with Epic Games. He graduated from Maryland Institute College of Art in 2017 with a Bachelor of Fine Arts in Animation. Additionally, he has volunteered extensively with SIGGRAPH and SIGGRAPH Asia since 2015.</p>
<h3>Day 2: </h3>
<h4>9:05 &#8211; Invited Talk: Embree “There and back again…” (Carsten Benthin, Ingo Wald)</h4>
<p><strong>Abstract</strong>: Looking back at the origins of Embree, how it developed through the years and some of the (surprising) issues it faced along its long journey towards an Academy Award.</p>
<p><strong>Carsten Benthin</strong></p>
<p><img loading="lazy" src="/assets/images/2021/Carsten-300x225.jpg" alt="" width="300" height="225" srcset="/assets/images/2021/Carsten-300x225.jpg 300w, /assets/images/2021/Carsten-768x576.jpg 768w, /assets/images/2021/Carsten-1024x768.jpg 1024w, /assets/images/2021/Carsten-972x729.jpg 972w, /assets/images/2021/Carsten.jpg 1092w" sizes="(max-width: 300px) 100vw, 300px" /></p>
<p>Carsten Benthin is a principal engineer at Intel Corporation responsible for researching, designing, implementing, and evaluating high performance visualization and rendering algorithms. He is the lead performance architect of the Embree Ray Tracing Kernels focusing on software and hardware optimizations for CPU and GPU architectures. Carsten holds a master&#8217;s degree in Computer Science and received his PhD on ray tracing optimizations for CPU architectures, both from Saarland University in Germany. Carsten published over 30 papers at top-tier conferences and holds 29 patents. His interest and expertise include computer graphics, high-performance rendering, low-level hardware optimizations, hardware design, parallel algorithms and programming.</p>
<p><strong>Ingo Wald</strong></p>
<p><img loading="lazy" src="/assets/images/2021/Ingo.png" alt="" width="134" height="134" /></p>
<p>Ingo Wald is a director at NVIDIA. He received his PhD from Saarland University and worked as a post-doctoral researcher at the Max Planck Institute for Informatics in Saarbruecken. He spent two years as a Research Professor at the Scientific Computing and Imaging Institute (SCI) and School of Computing at the University of Utah. Since 2005, Ingo was a member of the Intel Labs working on high-performance ray tracing, rendering, and visualization, hardware architectures for high-performance graphics, and SPMD compiler technology for such architecture. Since 2015, he has been an Adjunct Assistant Professor at the University of Utah and, in 2018, he joined NVIDIA. </p>
<h4>9:40 &#8211; Invited Talk: Grand challenges in synthetic radar data generation for AI (Karl Leiss, Matteo Marone)</h4>
<p><strong>Abstract: </strong>Raytracing is a powerful approach for the emulation of camera sensor outputs. How about using it for radar sensor simulation? What are the relevant aspects to generate synthetic radar data in the domain of autonomous mobility?</p>
<p>The talk outlines challenges towards the adoption of raytracing for physical based electromagnetic wave simulation and where to derive meta data from, needed by AI to classify objects based on their radar signature.</p>
<p>In addition physical based radar simulation is compute power intense &#8211; what is the potential of the latest hardware products and their optimized libraries to boost performance.</p>
<p><strong>Company information: </strong></p>
<p>BIT technology generates photo-realistic 3D models of our world. Building on real-world 3D data, they have built an advanced content generation pipeline, which produces the ground truth for deep learning and validation of artificial intelligence. BIT’s technology aims at a scalable creation, with ultra-detailed resolution and fast variation of scenarios. Their applications target future mobility for which 3D data matching the real world is mandatory. </p>
<p><strong>Short biography for Karl:</strong></p>
<p>„Karl Leiss is the CEO of BIT Technology Solutions, that was founded in 2014. He founded his first company in 2004 with the scope of test benches for embedded real-time systems and the development of energy recovery systems for motorsports based on his university background in mechanical engineering and computer science. From 2011 on he worked in the semiconductor industry on embedded PowerPC devices for high speed signal processing and established as product manager one of the largest ISO26262 ready microcontroller families in the industry.“</p>
<p><strong>Short biography for Matteo:</strong></p>
<p>&#8220;Dr. Matteo Marone is the Senior Physics Engineer for BIT Technology Solutions. He got his Ph.D in High Energy Physics at the University of Turin and post-doc at the University of Trieste. He was involved for 10 years in the construction, calibration and data analysis of the Compact Muon Solenoid experiment (CMS), one of the particle physics experiments that are currently taking data at CERN in Geneva. Since 2014 he has been working for private companies in sensor R&amp;D and simulations.&#8221;</p>
<h3>Day 3:</h3>
<h4>9:05 &#8211; Invited Talk: Fireballs and Lightning: Visualising Esports Experiences (Anders Drachen)</h4>
<p><strong>Abstract: </strong>In the 25 bn esports industry, data is king. With detailed data from every single match being played across all levels of skill, covering uncounted hundreds of thousands of years of playtime, there is no bottom in the ocean of data that we can analyse and visualise.</p>
<p>The availability of data, the digital nature of the games, the technical infrastructure and the surrounding young audiences has led esports to become a rapidly innovating sector, which is constantly striving to invent new ways of engaging audiences. More than half a billion people play esports games regularly, and the audiences are young, technologically in the forefront and keen to be involved in the experience, as opposed to traditional one-size-fits-all sports broadcasting. They are the audience of the future, and esports has become a testbed for new entertainment technologies, with companies launching new initiatives on a daily basis. Jointly, this has launched esports as the fastest growing entertainment sector worldwide.</p>
<p>On this exciting background, the UKRI/Innovate UK Demonstrator project Weavr was launched in 2019 as a collaboration between seven companies and the University of York. Weavr has since its inception launched data-driven, interactive and personalised audience-facing experienced across mobile platforms, VR, AR, 2nd screen, and other formats, all utilising data from esports matches to tell stories with data. 27 million views and 8 million users later, Weavr is ready to present some experiences from the project and highlight the potential impact of data visualization in esports.</p>
<p><strong>Anders Drachen</strong></p>
<p><img loading="lazy" src="/assets/images/2021/anders-300x300.jpg" alt="" width="300" height="300" srcset="/assets/images/2021/anders-300x300.jpg 300w, /assets/images/2021/anders-150x150.jpg 150w, /assets/images/2021/anders.jpg 400w" sizes="(max-width: 300px) 100vw, 300px" /></p>
<p>Anders Drachen is recognized as one of the world’s most influential people in business intelligence in the Creative Industries, and a core innovator in the domain. His work has assisted major international game publishers, as well as SMEs, make better decisions based on their data. He currently serves as Professor at the Department of Computer Science, University of York. He is the Lead Analyst of the UKRI Audience of the Future Demonstrator <a href="https://weavr.tv/">Weavr</a>. which is building new data-driven audience experiences across esports and sports. He is also the manager of the <a href="https://arc.york.ac.uk/">Arena Research Cluster</a>, an international research network focused on innovation in esports and sports. His award-winning research has seen worldwide media coverage, and his books have seen hundreds of thousands of downloads, forming standard works of reference in-game data science and games user research. In his private life, he writes books for children about technology and economics.</p>
<h4>9:40 &#8211; Invited Talk: Modeling user behavior for improved virtual reality applications (Belen Masia)</h4>
<p><strong>Abstract: </strong>Virtual Reality (VR) can dramatically change the way we create and consume content in areas of our everyday life, including entertainment, training, design, communication or advertising. Understanding how people explore immersive virtual environments (VE), and how they behave in them, is crucial for many applications in VR, such as designing content, developing new compression algorithms, or improving the interaction with virtual humans. This talk will give an overview of our work in this area, including modeling viewing behavior in VE, imperceptible manipulation of camera motion, or sensory degradation under certain circumstances.</p>
<p><strong>Belen Masia</strong></p>
<p><img loading="lazy" class="alignnone size-medium wp-image-133" src="/assets/images/2021/belen-276x300.png" alt="" width="276" height="300" srcset="/assets/images/2021/belen-276x300.png 276w, /assets/images/2021/belen.png 607w" sizes="(max-width: 276px) 100vw, 276px" /></p>
<p>Belen Masia is a tenured Associate Professor in the Computer Science Department at Universidad de Zaragoza, and a member of the Graphics and Imaging Lab. Before, she was a postdoctoral researcher at the Max Planck Institute for Informatics. Her research focuses on the areas of computational imaging, applied perception, and virtual reality. Belen Masia is a Eurographics Junior Fellow. She is also the recipient of a Eurographics Young Researcher Award in 2017, a Eurographics PhD Award in 2015, an award to the top ten innovators below 35 in Spain from MIT Technology Review in 2014, and an NVIDIA Graduate Fellowship in 2012. She currently serves as an Associate Editor for ACM Transactions on Graphics. She is the co-founder of the startup DIVE Medical.</p>
<p>&nbsp;</p>
<h3>Day 4:</h3>
<h4>12:00 &#8211; Keynote: High performance Interfaces for Modeling, Animation and more&#8230; (Karan Singh)</h4>
<p><strong>Draft Abstract:</strong> Creating and modifying 3D content is difficult. Sketch and sculpt interfaces are a promising medium of visual communication but there are a number of inherent limitations in human motor control, drawing skill, perception, and the ambiguities of inference, that make the leap from 2D input to 3D shape a challenging task. Similarly, creating facial animation is difficult. In this context, aspects of facial anatomy, biomechanics, linguistics and perceptual psychology should be considered for the construction of geometric face rigs, and techniques for the animator-centric creation of emotion, expression and speech animation from input images, audio and video. Finally, AR/VR offers new means of rethinking interaction, in particular the near quarter century old internet browser design of Mosaic and its successors. This talk will investigate novel solutions to address these challenges.</p>
<p><strong>Karan Singh</strong></p>
<p><img loading="lazy" src="/assets/images/2021/karan-206x300.png" alt="" width="206" height="300" srcset="/assets/images/2021/karan-206x300.png 206w, /assets/images/2021/karan.png 274w" sizes="(max-width: 206px) 100vw, 206px" /></p>
<p>Karan Singh is a Professor of Computer Science at the University of Toronto. He co-directs a globally reputed graphics and HCI lab, DGP, has over 100 peer-reviewed publications, and has supervised over 40 MS/PhD theses. His research interests lie in interactive graphics, spanning art and visual perception, geometric design and fabrication, character animation and anatomy, and interaction techniques for mobile, Augmented and Virtual Reality (AR/VR). He has been a technical lead for the Oscar award winning software Maya and was the R&amp;D Director for the 2004 Oscar winning animated short Ryan. He has co-founded multiple companies including Arcestra (architectural design), JALI (facial animation),  and JanusVR (Virtual Reality).</p>
